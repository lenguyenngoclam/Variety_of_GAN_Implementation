{"cells":[{"cell_type":"code","execution_count":1,"id":"SIhW1fTJ01eW","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8397,"status":"ok","timestamp":1689730849911,"user":{"displayName":"Lâm Lê","userId":"10908577340893694337"},"user_tz":-420},"id":"SIhW1fTJ01eW","outputId":"bfcf56bf-9ffe-420a-c37c-8092a8dc5ac9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting opendatasets\n","  Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from opendatasets) (4.65.0)\n","Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (from opendatasets) (1.5.15)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from opendatasets) (8.1.4)\n","Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (1.16.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2023.5.7)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.8.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.27.1)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (8.0.1)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (1.26.16)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (6.0.0)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle->opendatasets) (0.5.1)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.4)\n","Installing collected packages: opendatasets\n","Successfully installed opendatasets-0.1.22\n","Collecting tensorflow-addons\n","  Downloading tensorflow_addons-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (612 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m612.1/612.1 kB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (23.1)\n","Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons)\n","  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n","Installing collected packages: typeguard, tensorflow-addons\n","Successfully installed tensorflow-addons-0.21.0 typeguard-2.13.3\n"]}],"source":["!pip install opendatasets\n","!pip install tensorflow-addons"]},{"cell_type":"markdown","id":"b8c5bac8-8d10-4d1e-a1b4-422f6b506d3b","metadata":{"id":"b8c5bac8-8d10-4d1e-a1b4-422f6b506d3b"},"source":["## Import required package"]},{"cell_type":"code","execution_count":null,"id":"6229bf84-09f9-48ae-9f95-753dd5946807","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14632,"status":"ok","timestamp":1689730892778,"user":{"displayName":"Lâm Lê","userId":"10908577340893694337"},"user_tz":-420},"id":"6229bf84-09f9-48ae-9f95-753dd5946807","outputId":"6051beb6-4b5a-4866-8f4c-64040c76ce49"},"outputs":[],"source":["from data_loader import DataLoader\n","from discriminator import Discriminator\n","from generator import Generator\n","from utils import plot_generator_loss, generate_and_visualize, plot_loss\n","\n","import tensorflow as tf\n","import time\n","from tqdm import tqdm\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.losses import MeanSquaredError, MeanAbsoluteError\n","import os\n","import matplotlib.pyplot as plt\n","\n","from IPython import display\n","import imageio.v2 as imageio\n","import config\n","\n","import opendatasets as od"]},{"cell_type":"markdown","id":"a9927c68-e301-4cf3-83e8-653c323d6eca","metadata":{"id":"a9927c68-e301-4cf3-83e8-653c323d6eca"},"source":["## Prepare dataset"]},{"cell_type":"code","execution_count":5,"id":"Yweu5qFe1Gzm","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":83676,"status":"ok","timestamp":1689730976447,"user":{"displayName":"Lâm Lê","userId":"10908577340893694337"},"user_tz":-420},"id":"Yweu5qFe1Gzm","outputId":"708b142e-c83a-421a-b379-015068c2ca91"},"outputs":[{"name":"stdout","output_type":"stream","text":["Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n","Your Kaggle username: lamlenn\n","Your Kaggle Key: ··········\n","Downloading monet2photo.zip to ./monet2photo\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 291M/291M [00:17<00:00, 17.6MB/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n"]}],"source":["# Dataset link : https://www.kaggle.com/datasets/balraj98/monet2photo\n","od.download('https://www.kaggle.com/datasets/balraj98/monet2photo')"]},{"cell_type":"code","execution_count":6,"id":"4062e302-fc2e-467e-bf25-59e83aaca58b","metadata":{"executionInfo":{"elapsed":5593,"status":"ok","timestamp":1689730982037,"user":{"displayName":"Lâm Lê","userId":"10908577340893694337"},"user_tz":-420},"id":"4062e302-fc2e-467e-bf25-59e83aaca58b"},"outputs":[],"source":["train_dataset = DataLoader(config.TRAIN_X_PATH, config.TRAIN_Y_PATH) \\\n","                        .get_dataset(config.BATCH_SIZE, config.BUFFER_SIZE, config.SHUFFLE)\n","val_dataset = DataLoader(config.VAL_X_PATH, config.VAL_Y_PATH) \\\n","                        .get_dataset(config.BATCH_SIZE, config.BUFFER_SIZE, False)"]},{"cell_type":"markdown","id":"45188a79-777e-4a0c-8a70-f6479169ea1a","metadata":{"id":"45188a79-777e-4a0c-8a70-f6479169ea1a"},"source":["## Train model"]},{"cell_type":"code","execution_count":null,"id":"3d02aa06-a28f-40d7-b422-1877e661a6c2","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"19KqW4tTc-7kaz3hoTrq9USRotJ8ZK6Xg"},"id":"3d02aa06-a28f-40d7-b422-1877e661a6c2","outputId":"b92d2aae-7165-4b98-a268-4151e5fc5ae6"},"outputs":[{"data":{"text/plain":["Output hidden; open in https://colab.research.google.com to view."]},"metadata":{},"output_type":"display_data"}],"source":["# Create optimizer\n","gen_optim = Adam(learning_rate=config.LEARNING_RATE, beta_1=config.BETA_1, beta_2=config.BETA_2)\n","disc_optim = Adam(learning_rate=config.LEARNING_RATE, beta_1=config.BETA_1, beta_2=config.BETA_2)\n","\n","# Initialize generator and discriminator\n","gen_g = Generator()\n","gen_f = Generator()\n","disc_X = Discriminator()\n","disc_Y = Discriminator()\n","\n","# Create checkpoint\n","checkpoint = tf.train.Checkpoint(gen_optim=gen_optim, disc_optim=disc_optim,\n","                                gen_g=gen_g, gen_f=gen_f, disc_x=disc_X, disc_y=disc_Y)\n","\n","# Prepare val input\n","test_inputs = []\n","test_targets = []\n","for x, y in val_dataset.take(6):\n","    test_inputs.append(x)\n","    test_targets.append(y)\n","test_inputs = tf.concat(test_inputs, axis=0)\n","test_targets = tf.concat(test_targets, axis=0)\n","\n","# Variable for tracing image\n","num_iter=15\n","\n","def train(dataset, continue_training=False, checkpoint_dir=None, start_epoch=0, num_iter=0):\n","    if continue_training:\n","        checkpoint.restore(checkpoint_dir)\n","\n","    G_losses = []\n","    D_losses = []\n","    # Initialize loss\n","    mse_loss = MeanSquaredError()\n","    mae_loss = MeanAbsoluteError()\n","\n","    for epoch in range(start_epoch, config.EPOCHS):\n","        start = time.perf_counter()\n","\n","        for batch_idx, (x_image, y_image) in enumerate(tqdm(dataset)):\n","            # Train discriminator X and discriminator Y\n","            with tf.GradientTape() as d_tape:\n","                fake_image_G = gen_g(x_image, training=True)\n","                true_disc_Y = disc_Y(y_image, training=True)\n","                disc_Y_true_loss = mse_loss(tf.ones_like(true_disc_Y), true_disc_Y)\n","                fake_disc_Y = disc_Y(fake_image_G, training=True)\n","                disc_Y_fake_loss = mse_loss(tf.zeros_like(fake_disc_Y), fake_disc_Y)\n","\n","                # Total loss of discriminator Y\n","                disc_Y_loss = disc_Y_true_loss + disc_Y_fake_loss\n","\n","                fake_image_F = gen_f(y_image, training=True)\n","                true_disc_X = disc_X(x_image, training=True)\n","                disc_X_true_loss = mse_loss(tf.ones_like(true_disc_X), true_disc_X)\n","                fake_disc_X = disc_X(fake_image_F, training=True)\n","                disc_X_fake_loss = mse_loss(tf.zeros_like(fake_disc_X), fake_disc_X)\n","\n","                # Total loss of discriminator X\n","                disc_X_loss = disc_X_true_loss + disc_X_fake_loss\n","\n","                # Total loss of discriminator in object function.\n","                # Slow down the discriminator by dividing the object by 2.\n","                disc_loss = (disc_Y_loss + disc_X_loss) / 2.0\n","\n","            # Calculate gradients\n","            disc_grads = d_tape.gradient(disc_loss, list(disc_X.trainable_variables) + list(disc_Y.trainable_variables))\n","            # Update weights\n","            disc_optim.apply_gradients(zip(disc_grads, list(disc_X.trainable_variables) + list(disc_Y.trainable_variables)))\n","\n","            # Monitor loss\n","            D_losses.append(disc_loss)\n","\n","            # Train Generator X and Generator Y\n","            with tf.GradientTape() as g_tape:\n","                # Adversarial loss of gen X and gen Y\n","                fake_image_G = gen_g(x_image, training=True)\n","                fake_disc_Y = disc_Y(fake_image_G, training=True)\n","                disc_Y_fake_loss = mse_loss(tf.ones_like(fake_disc_Y), fake_disc_Y)\n","\n","                fake_image_F = gen_f(y_image, training=True)\n","                fake_disc_X = disc_X(fake_image_F, training=True)\n","                disc_X_fake_loss = mse_loss(tf.ones_like(fake_disc_X), fake_disc_X)\n","\n","                # Consistency Loss of gen X and gen Y\n","                consistence_loss_X = mae_loss(x_image, gen_f(fake_image_G))\n","                consistence_loss_Y = mae_loss(y_image, gen_g(fake_image_F))\n","                # Total loss of Generator X and Generator Y\n","                gen_loss = disc_Y_fake_loss + disc_X_fake_loss \\\n","                            + config.CONSISTENCY_LOSS_LAMBDA * consistence_loss_X \\\n","                            + config.CONSISTENCY_LOSS_LAMBDA * consistence_loss_Y\n","\n","            # Calculate gradients\n","            gen_grads = g_tape.gradient(gen_loss, list(gen_g.trainable_variables) + list(gen_f.trainable_variables))\n","            # Update weights\n","            gen_optim.apply_gradients(zip(gen_grads, list(gen_g.trainable_variables) + list(gen_f.trainable_variables)))\n","\n","            # Monitor loss\n","            G_losses.append(gen_loss)\n","\n","            # Print result for monitoring\n","            if (batch_idx + 1) % 200 == 0 and batch_idx > 0:\n","                # Monitor training process\n","                display.clear_output(wait=True)\n","                print(f'Traning from batch {batch_idx - 200} to batch {batch_idx} \\\n","                            takes {time.perf_counter() - start} seconds')\n","                print(\n","                    f\"Epoch [{epoch}/{config.EPOCHS}] Batch {batch_idx}/{len(dataset)} \\\n","                      Loss D: {disc_loss:.4f}, loss G: {gen_loss:.4f}\"\n","                )\n","                generate_and_visualize(gen_g, test_inputs, num_iter)\n","                plot_loss(G_losses, D_losses)\n","                num_iter += 1\n","\n","            if (batch_idx + 1) % 3000 == 0:\n","                checkpoint.save(config.checkpoint_prefix)\n","\n","    print('Done!')\n","    # Display the last result\n","    display.clear_output(wait=True)\n","    print(f'Traning epoch {epoch} takes {time.perf_counter() - start} seconds')\n","    generate_and_visualize(gen_g, test_inputs, config.EPOCHS)\n","    plot_loss(G_losses, D_losses)\n","\n","train(train_dataset, num_iter=num_iter, continue_training=True, checkpoint_dir=config.checkpoint_prefix + '-1')"]},{"cell_type":"code","execution_count":5,"id":"7d62b68a-1e48-47b7-a0d2-8164e4c54315","metadata":{"id":"7d62b68a-1e48-47b7-a0d2-8164e4c54315"},"outputs":[],"source":["import imageio.v2  as imageio\n","with open('cycleGAN_training_process.gif', 'w+'):\n","    pass\n","\n","frames = []\n","for epoch in range(67):\n","    image = imageio.imread('training-images/image_at_epoch_{:04d}.png'.format(epoch))\n","    frames.append(image)\n","\n","imageio.mimsave('cycleGAN_training_process.gif', frames)\n","\n","# this is a hack to display the gif inside the notebook\n","#os.system('cp cycleGAN_training_process.gif cycleGAN_training_process.gif.png')\n","\n","#display.Image(filename=\"pix2pix_training_process.gif.png\")"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":5}
